{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue PySpark ETL Notebook for Weather Datalake Demo\n",
    "\n",
    "<img src=\"https://thecodinginterface-images.s3.amazonaws.com/blogposts/weather-data-lake/S3+Data+Lake.jpeg\">\n",
    "\n",
    "#### Purpose:\n",
    "\n",
    "- Convert string data types to appropriate numeric data types\n",
    "- Explode out nested, multi-valued fields, to be top level columns\n",
    "- Drop unneeded columns\n",
    "- Convert to Parquet format for more efficient downstream analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More or Less Obligatory / Boilerplate Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import FloatType, StringType, IntegerType, DateType\n",
    "\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue.utils import getResolvedOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glue_db = \"weatherdata\"\n",
    "s3_bkt = \"weather-data-collector-weatherdatalakes3bucket-1r8t1k304n84b\"\n",
    "rawweather_tbl = \"rawweatherdata\"\n",
    "output_s3_path = \"s3://{s3_bkt}/cleanweather\".format(s3_bkt=s3_bkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session and Glue ETL Job Context Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession(SparkContext.getOrCreate())\n",
    "glue_ctx = GlueContext(SparkContext.getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Glue Dynamic Data Frame Object from Glue Context and Glue Metadata Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dyf = glue_ctx.create_dynamic_frame.from_catalog(\n",
    "                        database=glue_db,\n",
    "                        table_name=rawweather_tbl\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Schema of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "|-- date: string\n",
      "|-- astronomy: array\n",
      "|    |-- element: struct\n",
      "|    |    |-- sunrise: string\n",
      "|    |    |-- sunset: string\n",
      "|    |    |-- moonrise: string\n",
      "|    |    |-- moonset: string\n",
      "|    |    |-- moon_phase: string\n",
      "|    |    |-- moon_illumination: string\n",
      "|-- maxtempC: string\n",
      "|-- maxtempF: string\n",
      "|-- mintempC: string\n",
      "|-- mintempF: string\n",
      "|-- avgtempC: string\n",
      "|-- avgtempF: string\n",
      "|-- totalSnow_cm: string\n",
      "|-- sunHour: string\n",
      "|-- uvIndex: string\n",
      "|-- hourly: array\n",
      "|    |-- element: struct\n",
      "|    |    |-- time: string\n",
      "|    |    |-- tempC: string\n",
      "|    |    |-- tempF: string\n",
      "|    |    |-- windspeedMiles: string\n",
      "|    |    |-- windspeedKmph: string\n",
      "|    |    |-- winddirDegree: string\n",
      "|    |    |-- winddir16Point: string\n",
      "|    |    |-- weatherCode: string\n",
      "|    |    |-- weatherIconUrl: array\n",
      "|    |    |    |-- element: struct\n",
      "|    |    |    |    |-- value: string\n",
      "|    |    |-- weatherDesc: array\n",
      "|    |    |    |-- element: struct\n",
      "|    |    |    |    |-- value: string\n",
      "|    |    |-- precipMM: string\n",
      "|    |    |-- precipInches: string\n",
      "|    |    |-- humidity: string\n",
      "|    |    |-- visibility: string\n",
      "|    |    |-- visibilityMiles: string\n",
      "|    |    |-- pressure: string\n",
      "|    |    |-- pressureInches: string\n",
      "|    |    |-- cloudcover: string\n",
      "|    |    |-- HeatIndexC: string\n",
      "|    |    |-- HeatIndexF: string\n",
      "|    |    |-- DewPointC: string\n",
      "|    |    |-- DewPointF: string\n",
      "|    |    |-- WindChillC: string\n",
      "|    |    |-- WindChillF: string\n",
      "|    |    |-- WindGustMiles: string\n",
      "|    |    |-- WindGustKmph: string\n",
      "|    |    |-- FeelsLikeC: string\n",
      "|    |    |-- FeelsLikeF: string\n",
      "|    |    |-- uvIndex: string\n",
      "|-- location: string\n",
      "|-- year: string\n",
      "|-- month: string\n",
      "|-- day: string"
     ]
    }
   ],
   "source": [
    "raw_dyf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make reusable Callback for Spark User Defined Function to Process Various Columns\n",
    "\n",
    "To be used to clean and aggregate nested multi-valued hourly column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_hourly(hours, key, fn):\n",
    "    nums = []\n",
    "    for hr in hours:\n",
    "        if hr[key]:\n",
    "            try:\n",
    "                num = float(hr[key])\n",
    "                if pd.notnull(num):\n",
    "                    nums.append(num)\n",
    "            except Exception as e:\n",
    "                logger.error({\n",
    "                    \"error\": str(e),\n",
    "                    \"message\": \"error converting {} to float\".format(hr[key])\n",
    "                })\n",
    "                raise e\n",
    "    if nums:\n",
    "        return float(fn(nums))\n",
    "\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create UDF to Calcuate Mean of Hourly Humidity Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_humidity = F.udf(lambda hours: process_hourly(hours, 'humidity', np.mean), FloatType())\n",
    "\n",
    "clean_df = raw_dyf.toDF().withColumn('avgHumidity',  avg_humidity('hourly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create UDF to Calc Min of Hourly Humidity Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_humidity = F.udf(lambda hours: process_hourly(hours, 'humidity', min), FloatType())\n",
    "\n",
    "clean_df = clean_df.withColumn('avgHumidity',  min_humidity('hourly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create UDF to Calc Max of Hourly Humidity Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_humidity = F.udf(lambda hours: process_hourly(hours, 'humidity', max), FloatType())\n",
    "\n",
    "clean_df = clean_df.withColumn('avgHumidity',  max_humidity('hourly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create UDF to Calc Total Precipitation From Hourly Precip Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_precipMM = F.udf(lambda hours: process_hourly(hours, 'precipMM', sum), FloatType())\n",
    "\n",
    "clean_df = clean_df.withColumn('totalPrecipMM', total_precipMM('hourly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok ... Glue / Spark is Useful Processing Nested Fields\n",
    "\n",
    "Create remaining UDFs to process the nested hourly field and apply them then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_pressure = F.udf(lambda hours: process_hourly(hours, 'pressure', np.mean), FloatType())\n",
    "min_pressure = F.udf(lambda hours: process_hourly(hours, 'pressure', min), FloatType())\n",
    "max_pressure = F.udf(lambda hours: process_hourly(hours, 'pressure', max), FloatType())\n",
    "\n",
    "clean_df = clean_df.withColumn(\n",
    "            'avgPressure', avg_pressure('hourly')\n",
    "        ).withColumn(\n",
    "            'minPressure', min_pressure('hourly')\n",
    "        ).withColumn(\n",
    "            'maxPressure', max_pressure('hourly')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Field Thats Should Be Numeric to Numeric Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- maxtempF: string (nullable = true)\n",
      " |-- mintempF: string (nullable = true)\n",
      " |-- avgtempF: string (nullable = true)\n",
      " |-- totalSnow_cm: string (nullable = true)\n",
      " |-- sunHour: string (nullable = true)\n",
      " |-- uvIndex: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "clean_df.select('maxtempF', 'mintempF', 'avgtempF', 'totalSnow_cm', 'sunHour', 'uvIndex').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_df = clean_df.withColumn(\n",
    "            'maxtempF', F.col('maxtempF').cast(FloatType())\n",
    "        ).withColumn(\n",
    "            'mintempF', F.col('mintempF').cast(FloatType())\n",
    "        ).withColumn(\n",
    "            'avgtempF', F.col('avgtempF').cast(FloatType())\n",
    "        ).withColumn(\n",
    "            'totalSnow_cm', F.col('totalSnow_cm').cast(FloatType())\n",
    "        ).withColumn(\n",
    "            'sunHour', F.col('sunHour').cast(FloatType())\n",
    "        ).withColumn(\n",
    "            'uvIndex', F.col('uvIndex').cast(IntegerType())\n",
    "        ).withColumn(\n",
    "            'date', F.col('date').cast(DateType())\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns We Are Not Interested In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_df = clean_df.drop('hourly', 'astronomy', 'mintempC', 'maxtempC', 'avgtempC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yay! Look at that Clean and Tidy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- maxtempF: float (nullable = true)\n",
      " |-- mintempF: float (nullable = true)\n",
      " |-- avgtempF: float (nullable = true)\n",
      " |-- totalSnow_cm: float (nullable = true)\n",
      " |-- sunHour: float (nullable = true)\n",
      " |-- uvIndex: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- avgHumidity: float (nullable = true)\n",
      " |-- totalPrecipMM: float (nullable = true)\n",
      " |-- avgPressure: float (nullable = true)\n",
      " |-- minPressure: float (nullable = true)\n",
      " |-- maxPressure: float (nullable = true)"
     ]
    }
   ],
   "source": [
    "clean_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+-----------+-----------+-------------+\n",
      "|      date|mintempF|avgtempF|maxtempF|avgHumidity|avgPressure|totalPrecipMM|\n",
      "+----------+--------+--------+--------+-----------+-----------+-------------+\n",
      "|2021-01-06|    33.0|    34.0|    35.0|       99.0|  1016.2917|          9.6|\n",
      "|2020-12-09|    46.0|    55.0|    63.0|       60.0|    1013.75|          0.0|\n",
      "|2021-01-21|    33.0|    38.0|    43.0|       72.0|  1015.8333|          0.0|\n",
      "|2021-01-05|    30.0|    37.0|    43.0|       89.0|  1014.3333|          0.7|\n",
      "|2021-02-04|    21.0|    26.0|    32.0|       94.0|   1006.875|          1.0|\n",
      "+----------+--------+--------+--------+-----------+-----------+-------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "selected = [\n",
    "    'date',\n",
    "    'mintempF',\n",
    "    'avgtempF',\n",
    "    'maxtempF',\n",
    "    'avgHumidity',\n",
    "    'avgPressure',\n",
    "    'totalPrecipMM'\n",
    "]\n",
    "clean_df.select(*selected).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Cleaned Data in Parquet Format Back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<awsglue.dynamicframe.DynamicFrame object at 0x7f7bfd4cd208>"
     ]
    }
   ],
   "source": [
    "clean_dyf = DynamicFrame.fromDF(\n",
    "    clean_df.repartition(\"location\", \"year\", \"month\"),\n",
    "    glue_ctx,\n",
    "    'cleanweather'\n",
    ")\n",
    "\n",
    "glue_ctx.purge_s3_path(output_s3_path, options={\"retentionPeriod\": 0})\n",
    "\n",
    "glue_ctx.write_dynamic_frame.from_options(\n",
    "    frame=clean_dyf,\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"path\": output_s3_path},\n",
    "    format=\"parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
