{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structured-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exterior-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"WeatherPySpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 adammcquistan  staff  96 Feb 21 21:49 \u001b[34mlocation=lincoln\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l rawweather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "graphic-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = spark.read.json(\"./rawweather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inner-beatles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- request: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- query: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- weather: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- astronomy: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- moon_illumination: string (nullable = true)\n",
      " |    |    |    |    |-- moon_phase: string (nullable = true)\n",
      " |    |    |    |    |-- moonrise: string (nullable = true)\n",
      " |    |    |    |    |-- moonset: string (nullable = true)\n",
      " |    |    |    |    |-- sunrise: string (nullable = true)\n",
      " |    |    |    |    |-- sunset: string (nullable = true)\n",
      " |    |    |-- avgtempC: string (nullable = true)\n",
      " |    |    |-- avgtempF: string (nullable = true)\n",
      " |    |    |-- date: string (nullable = true)\n",
      " |    |    |-- hourly: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- DewPointC: string (nullable = true)\n",
      " |    |    |    |    |-- DewPointF: string (nullable = true)\n",
      " |    |    |    |    |-- FeelsLikeC: string (nullable = true)\n",
      " |    |    |    |    |-- FeelsLikeF: string (nullable = true)\n",
      " |    |    |    |    |-- HeatIndexC: string (nullable = true)\n",
      " |    |    |    |    |-- HeatIndexF: string (nullable = true)\n",
      " |    |    |    |    |-- WindChillC: string (nullable = true)\n",
      " |    |    |    |    |-- WindChillF: string (nullable = true)\n",
      " |    |    |    |    |-- WindGustKmph: string (nullable = true)\n",
      " |    |    |    |    |-- WindGustMiles: string (nullable = true)\n",
      " |    |    |    |    |-- cloudcover: string (nullable = true)\n",
      " |    |    |    |    |-- humidity: string (nullable = true)\n",
      " |    |    |    |    |-- precipInches: string (nullable = true)\n",
      " |    |    |    |    |-- precipMM: string (nullable = true)\n",
      " |    |    |    |    |-- pressure: string (nullable = true)\n",
      " |    |    |    |    |-- pressureInches: string (nullable = true)\n",
      " |    |    |    |    |-- tempC: string (nullable = true)\n",
      " |    |    |    |    |-- tempF: string (nullable = true)\n",
      " |    |    |    |    |-- time: string (nullable = true)\n",
      " |    |    |    |    |-- uvIndex: string (nullable = true)\n",
      " |    |    |    |    |-- visibility: string (nullable = true)\n",
      " |    |    |    |    |-- visibilityMiles: string (nullable = true)\n",
      " |    |    |    |    |-- weatherCode: string (nullable = true)\n",
      " |    |    |    |    |-- weatherDesc: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- value: string (nullable = true)\n",
      " |    |    |    |    |-- weatherIconUrl: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- value: string (nullable = true)\n",
      " |    |    |    |    |-- winddir16Point: string (nullable = true)\n",
      " |    |    |    |    |-- winddirDegree: string (nullable = true)\n",
      " |    |    |    |    |-- windspeedKmph: string (nullable = true)\n",
      " |    |    |    |    |-- windspeedMiles: string (nullable = true)\n",
      " |    |    |-- maxtempC: string (nullable = true)\n",
      " |    |    |-- maxtempF: string (nullable = true)\n",
      " |    |    |-- mintempC: string (nullable = true)\n",
      " |    |    |-- mintempF: string (nullable = true)\n",
      " |    |    |-- sunHour: string (nullable = true)\n",
      " |    |    |-- totalSnow_cm: string (nullable = true)\n",
      " |    |    |-- uvIndex: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "catholic-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, explode, explode_outer\n",
    "from pyspark.sql.types import FloatType\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "assisted-world",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+\n",
      "|  a|  intlist|mapfield|\n",
      "+---+---------+--------+\n",
      "|  1|[1, 2, 3]|[a -> b]|\n",
      "+---+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={\"a\": \"b\"})])\n",
    "eDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adjacent-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(anInt=1), Row(anInt=2), Row(anInt=3)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eDF.select(explode(eDF.intlist).alias(\"anInt\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "danish-tennis",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a86544dcbfff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anInt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/intrado/architecture_guild/data-storage-talk/datalake/weather-data-collector/venv/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \"\"\"\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1401\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[1;32m   1402\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "eDF.select(explode(eDF.intlist).alias(\"anInt\")).mean().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continued-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+---+--------+--------------------+\n",
      "|location|year|month|day|avgtempC|              hourly|\n",
      "+--------+----+-----+---+--------+--------------------+\n",
      "| lincoln|2020|    1| 17|      -1|[[-12, 11, -14, 7...|\n",
      "| lincoln|2020|    1| 11|     -10|[[-15, 5, -20, -3...|\n",
      "| lincoln|2020|    1| 16|      -9|[[-19, -2, -18, 0...|\n",
      "| lincoln|2020|    1| 10|      -4|[[-1, 30, -3, 27,...|\n",
      "| lincoln|2020|    1|  8|       1|[[-5, 22, -4, 25,...|\n",
      "| lincoln|2020|    1|  7|       3|[[-5, 23, -4, 24,...|\n",
      "| lincoln|2020|    1|  3|       0|[[-2, 28, -5, 23,...|\n",
      "| lincoln|2020|    1| 12|      -9|[[-16, 4, -17, 1,...|\n",
      "| lincoln|2020|    1|  6|       2|[[-6, 22, -3, 28,...|\n",
      "| lincoln|2020|    1| 13|      -5|[[-10, 14, -12, 1...|\n",
      "| lincoln|2020|    1|  4|       1|[[-8, 18, -9, 16,...|\n",
      "| lincoln|2020|    1|  9|       5|[[1, 33, 1, 34, 4...|\n",
      "| lincoln|2020|    1|  2|       3|[[-2, 28, -2, 28,...|\n",
      "| lincoln|2020|    1| 15|      -5|[[-3, 27, -6, 22,...|\n",
      "| lincoln|2020|    1|  5|       4|[[-1, 30, -0, 31,...|\n",
      "| lincoln|2020|    1| 14|      -3|[[-4, 26, -6, 21,...|\n",
      "+--------+----+-----+---+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select('location', 'year', 'month', 'day', explode_outer('weather'))\\\n",
    "    .select('location', 'year', 'month', 'day', 'col.avgtempC', 'col.hourly').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competitive-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precip(items):\n",
    "    nums = [float(item['precipMM']) for item in items if item['precipMM']]\n",
    "    return np.mean(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "welsh-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precip_udf = udf(lambda x: avg_precip(x), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "opening-imperial",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`hourly`' given input columns: [day, location, month, request, weather, year];;\n'Project [request#7, weather#8, location#9, year#10, month#11, day#12, <lambda>('hourly) AS avg_precip_mm#20]\n+- Relation[request#7,weather#8,location#9,year#10,month#11,day#12] json\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9bffa9fc6965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg_precip_mm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_precip_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hourly'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/intrado/architecture_guild/data-storage-talk/datalake/weather-data-collector/venv/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \"\"\"\n\u001b[1;32m   2095\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/intrado/architecture_guild/data-storage-talk/datalake/weather-data-collector/venv/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/intrado/architecture_guild/data-storage-talk/datalake/weather-data-collector/venv/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/intrado/architecture_guild/data-storage-talk/datalake/weather-data-collector/venv/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`hourly`' given input columns: [day, location, month, request, weather, year];;\n'Project [request#7, weather#8, location#9, year#10, month#11, day#12, <lambda>('hourly) AS avg_precip_mm#20]\n+- Relation[request#7,weather#8,location#9,year#10,month#11,day#12] json\n"
     ]
    }
   ],
   "source": [
    "weather = weather.withColumn('avg_precip_mm', avg_precip_udf('hourly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimum-optimization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             weather|\n",
      "+--------------------+\n",
      "|[[[[47, Last Quar...|\n",
      "|[[[[100, Full Moo...|\n",
      "|[[[[54, Waning Gi...|\n",
      "|[[[[100, Full Moo...|\n",
      "|[[[[88, Waxing Gi...|\n",
      "|[[[[80, Waxing Gi...|\n",
      "|[[[[51, First Qua...|\n",
      "|[[[[83, Waxing Gi...|\n",
      "|[[[[73, Waxing Gi...|\n",
      "|[[[[76, Waning Gi...|\n",
      "|[[[[59, First Qua...|\n",
      "|[[[[95, Waxing Gi...|\n",
      "|[[[[44, First Qua...|\n",
      "|[[[[61, Waning Gi...|\n",
      "|[[[[66, First Qua...|\n",
      "|[[[[69, Waning Gi...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select('weather').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "surprising-building",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+\n",
      "| id|  an_array|     a_map|\n",
      "+---+----------+----------+\n",
      "|  1|[foo, bar]|[x -> 1.0]|\n",
      "|  2|        []|        []|\n",
      "|  3|      null|      null|\n",
      "+---+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(1, [\"foo\", \"bar\"], {\"x\": 1.0}), (2, [], {}), (3, None, None)],\n",
    "    (\"id\", \"an_array\", \"a_map\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-purple",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
